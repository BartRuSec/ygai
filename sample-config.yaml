# Sample configuration for ygai
# Copy this file to .ygai/config.yaml in your home directory or current directory

models:
  # Default model configuration (mandatory)
  default:
    provider: "@langchain/openai"
    model: "gpt-4"
    # Replace with your actual API key
    apiKey: "your-openai-api-key"
    temperature: 0.7
  
  # Additional model configurations
  anthropic:
    provider: "@langchain/anthropic"
    model: "claude-3-7-sonnet-202502219"
    # Replace with your actual API key
    apiKey: "your-anthropic-api-key"
    temperature: 0.7
  
  # Example of a openrouter
  openrouter-deepseek:
    provider: "@langchain/openai"
    model: "deepseek/deepseek-chat-v3-0324:free"
    # Replace with your actual API key and endpoint
    apiKey: "your-openrouter-key"
    configuration: 
      baseURL: https://openrouter.ai/api/v1
  # Example of local model configuration (development only)
  # WARNING: agent:unsecure disables certificate checking - use only for development with local models
  local-model:
    provider: "@langchain/openai"
    model: "llama-3.1-8b-instruct"
    apiKey: "not-needed-for-local"
    configuration:
      baseURL: "http://localhost:1234/v1"
      agent: unsecure  # Disables HTTPS certificate checking - DEVELOPMENT ONLY
  
  # Advanced configuration example using _type and _module for custom HTTP agent
  advanced-custom:
    provider: "@langchain/openai"
    model: "gpt-4"
    apiKey: "your-openai-api-key"
    configuration:
      baseURL: "https://api.openai.com/v1"
      # Custom HTTP agent with specific configuration
      httpAgent:
        _type: "Agent"
        _module: "https"
        timeout: 10000
        keepAlive: true
        maxSockets: 5
        maxFreeSockets: 2
  
  # Example with inline function for request transformation
  inline-function-example:
    provider: "@langchain/openai"
    model: "gpt-4"
    apiKey: "your-openai-api-key"
    configuration:
      # Custom request transformer using inline function
      requestTransformer:
        _inline: |
          () => {
            return (request) => {
              // Add custom headers
              return {
                ...request,
                headers: {
                  ...request.headers,
                  'X-Custom-Client': 'ygai',
                  'X-Request-ID': Math.random().toString(36).substr(2, 9)
                }
              };
            };
          }

# MCP (Model Context Protocol) server configurations
mcp:
  # Math server using STDIO transport
  math:
    transport: "stdio"
    command: "npx"
    args: ["-y", "@modelcontextprotocol/server-math"]
    restart:
      enabled: true
      maxAttempts: 3
      delayMs: 1000
  
  # Filesystem server using STDIO transport
  filesystem:
    transport: "stdio"
    command: "npx"
    args: ["-y", "@modelcontextprotocol/server-filesystem", "/path/to/allowed/directory"]
    restart:
      enabled: true
      maxAttempts: 3
      delayMs: 1000
  
  # Example HTTP/SSE server
  weather:
    url: "https://example.com/weather/mcp"
    headers:
      Authorization: "Bearer your-api-token"
    automaticSSEFallback: false
    reconnect:
      enabled: true
      maxAttempts: 5
      delayMs: 2000
  
  # Example SSE server
  github:
    transport: "sse"
    url: "https://example.com/mcp"
    reconnect:
      enabled: true
      maxAttempts: 5
      delayMs: 2000

prompts:
  # Default prompt configuration
  default:
    system: "You are a helpful assistant. Respond to the user's request in a clear and concise manner."
  
  # Translate prompt with hooks example
  translate:
    vars: [language]  # Required variables
    alias: t
    system: "Translate this text to {language}. Respond with only the translated text, no explanations or additional text."
    # Example hooks (uncomment to use)
    # pre:
    #   file: "./examples/hooks/translatePre.js"
    #   function: "prepareText"
    # post:
    #   file: "./examples/hooks/translatePost.js"
    #   function: "validateTranslation"
  
  # Summarize prompt
  summarize:
    alias: s
    system: "Summarize the following text or a files in the context in a concise manner. Focus on the key points and main ideas."
  
  # Code prompt
  code:
    alias: c
    system: "You are a coding assistant. Provide clean, well-documented code examples in response to the user's request. Include explanations where helpful."
  
  # Shell command prompt
  sh:
    system: "Provide only zsh code to be executed base on user request."
  
  # Date prompt
  date:
    alias: d
    system: "You are a system utility. Respond with only the requested information in JSON format."
    user: "Provide the current date and time."
  
  # Example of file-based prompts
  file-example:
    alias: fe
    system:
      file: "./prompts/system.txt"
    user:
      file: "./prompts/user.md"
  
  # Mixed format example
  mixed-example:
    system: "You are a helpful assistant."
    user:
      file: "~/prompts/user-template.txt"
  
  # MCP-enabled prompts
  math-helper:
    alias: m
    system: "You are a math assistant with access to calculation tools. Use the available math tools to solve complex calculations accurately."
    mcp: ["math"]
  
  file-analyzer:
    alias: fa
    system: "You are a file analysis assistant. You can read and analyze files from the filesystem and perform mathematical calculations on data."
    mcp: ["filesystem", "math"]
  
  weather-assistant:
    alias: w
    system: "You are a weather assistant with access to weather data. Provide current weather information and forecasts."
    mcp: "weather"
  
  research-assistant:
    alias: ra
    system: "You are a research assistant with access to multiple tools including file system access, mathematical calculations, and external data sources."
    mcp: ["filesystem", "math", "weather"]
